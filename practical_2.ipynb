{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c669ff-a233-4034-b7cb-6214df110641",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text pre-processing & train/test set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0b5dfef-854c-4d9f-8d00-56aec9b1c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72dbe132-8819-46fb-b9b0-92e811ae8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e25b221-70e3-4311-ae07-c5c7f83d6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0598e12b-321c-48d4-b1e9-5b2bf396ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_train[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e590d02-e9cc-4659-beec-368f9fd6a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_train[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4329389e-0f68-46d8-9aff-25540e2520b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_test[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d026a776-5291-4a41-8166-af556783e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_test[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf4c1da4-006d-4aae-81e3-3da8c0f40f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat deceptive and truthful dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0306e899-4798-4ef1-a73a-419dca9e5932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel is located 1/2 mile from the train stati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I made my reservation at the Hilton Chicago be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When most people think Hilton, they think luxu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I recently stayed stayed at the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I booked a room at the Hilton Chic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>The Palmer House has a beautiful lobby with a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>great expectations from the hotel of THE FUGIT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>For a Hilton hotel I was very unimpressed, the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Beautiful historic hotel -- and since I'm in h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>The heating in our room didn't work and wasn't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Label\n",
       "0    Hotel is located 1/2 mile from the train stati...      0\n",
       "1    I made my reservation at the Hilton Chicago be...      0\n",
       "2    When most people think Hilton, they think luxu...      0\n",
       "3    My husband and I recently stayed stayed at the...      0\n",
       "4    My wife and I booked a room at the Hilton Chic...      0\n",
       "..                                                 ...    ...\n",
       "795  The Palmer House has a beautiful lobby with a ...      1\n",
       "796  great expectations from the hotel of THE FUGIT...      1\n",
       "797  For a Hilton hotel I was very unimpressed, the...      1\n",
       "798  Beautiful historic hotel -- and since I'm in h...      1\n",
       "799  The heating in our room didn't work and wasn't...      1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([deceptive_train, truthful_train, deceptive_test, truthful_test], axis=0).reset_index(drop=True)\n",
    "df\n",
    "#640-800 = test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68973e-c5ab-40fc-9fd9-9c8158624077",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Further text pre-processing \n",
    "\n",
    "- Tokenization\n",
    "- Lower-casing\n",
    "- Punctuation & Special character removal\n",
    "- Spelling correction\n",
    "- Stop-word removal\n",
    "- (Stemming (Porter)) *Skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e78e5ed3-155a-4101-90aa-e535db7ef7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords # stopwords.words('english')\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ddaafcd-569a-4b58-b898-ce567df33f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in nltk.word_tokenize(x)]) # Tokenize\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [word.lower() for word in x]) # Apply lower-casing\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in string.punctuation]) # Punctuation removal\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in ' '.join(stopwords.words('english'))]) # Stop word removal\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [re.sub(\"(?:\\W|\\d)+\", \"\", word) for word in x]) # Removing special chars and numbers\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word != \"\"]) # Remove empty strings\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: [str(TextBlob(word).correct()) for word in x]) # Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c5f4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"./df1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "afd04f48-bcba-4d4b-a1cf-4e72ffca5ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hotel, located, mile, train, station, quite, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[made, reservation, hilton, chicago, believing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[people, think, hilton, think, luxury, know, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[husband, recently, stayed, stayed, hilton, ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wife, booked, room, hilton, chicago, three, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  [hotel, located, mile, train, station, quite, ...      0\n",
       "1  [made, reservation, hilton, chicago, believing...      0\n",
       "2  [people, think, hilton, think, luxury, know, w...      0\n",
       "3  [husband, recently, stayed, stayed, hilton, ch...      0\n",
       "4  [wife, booked, room, hilton, chicago, three, w...      0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle the df. Pickled the df in case the kernel dies when fitting the models, because the spelling correction above takes a while to execute\n",
    "df = pd.read_pickle(\"./df1.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8fb9867-2cb1-41d2-a4fb-04741db6aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to str to construct dtm with sklearn CountVectorizer\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f813387-d5fb-44d0-9403-0a115976f830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel located mile train station quite like tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>made reservation hilton chicago believing goin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people think hilton think luxury know wish hal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>husband recently stayed stayed hilton chicago ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wife booked room hilton chicago three weekend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  hotel located mile train station quite like tr...      0\n",
       "1  made reservation hilton chicago believing goin...      0\n",
       "2  people think hilton think luxury know wish hal...      0\n",
       "3  husband recently stayed stayed hilton chicago ...      0\n",
       "4  wife booked room hilton chicago three weekend ...      0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32a8faa7-6b77-4108-aeb9-15f37c143a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high hopes hilton chicago sad say disappointed outrageous expensive two people one night expect pay park car offer free wife instead pay get internet room wait pm check even though flight morning rent car airport hotel offer transportation stress hilton chicago hotel bar either doubt stay\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Text\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "97424070-aa83-4d06-9031-a38099a6fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Set ngram=1,2, 1,2 and 2,2 (only bigrams) and min_df (float 0-1) for Naive Bayes when needed (use diff thresholds 0.005 increment starting at 1% -> 10%).\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), min_df=1, lowercase=False)\n",
    "X = vectorizer.fit_transform(df[\"Text\"])\n",
    "# X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6d3c544-5217-4f97-ba8e-14700719f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6504)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34b341bb-91ec-4072-a0dc-ba6be085f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advances'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d99f-d4ab-48b2-a15e-df0777db4081",
   "metadata": {},
   "source": [
    "#### Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "473e43a0-190f-48c2-977a-dc4e5574d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[0:640], df[\"Label\"][0:640].to_numpy()\n",
    "X_test, y_test = X[640:], df[\"Label\"][640:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62e3b7-4a19-41a4-b4a5-9213d01dae5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models using unigram only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1d5ee94-9774-4956-851a-97b4bb87ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3939a21e-f149-4d43-b9f7-c013040b117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def performance_metrics(y_true, y_pred):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cf_matrix.ravel()\n",
    "    \n",
    "    accuracy = (tn+tp)/(tn+tp+fp+fn)\n",
    "    recall =  (tp)/(tp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    \n",
    "    return (accuracy, recall, precision, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56636b49-b51f-47f4-acce-34812e765b87",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79639b76-8ad8-4e17-800e-675f63cd76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d65318f-3870-4004-b564-f27a07d407e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-03a19e05e3ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Return X_train/X_test for which CV score was best (best doc frequency threshold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mbest_thresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_NB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (score.mean(), X_train, X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-03a19e05e3ba>\u001b[0m in \u001b[0;36mcv_NB\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Only need to change X_train/test, y_train/test remains same (only removing/adding columns, not rows)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0m\u001b[0;32m   1223\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[1;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[0;32m   1094\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "def cv_NB():\n",
    "    \n",
    "    # Find best threshold\n",
    "    \n",
    "    thresholds = np.arange(0.01, 10, 0.001)\n",
    "    \n",
    "    cv_scores = []\n",
    "    for thresh in thresholds:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,1), min_df=thresh, lowercase=False)\n",
    "        X = vectorizer.fit_transform(df[\"Text\"]) \n",
    "        X_train = X[0:640] # Only need to change X_train/test, y_train/test remains same (only removing/adding columns, not rows)\n",
    "        X_test = X[640:]\n",
    "        score = cross_val_score(MultinomialNB(), X_train, y_train)\n",
    "        cv_scores.append((score.mean(), X_train, X_test))\n",
    "    \n",
    "    return max(cv_scores, key=lambda x: x[0]) # Return X_train/X_test for which CV score was best (best doc frequency threshold)\n",
    "        \n",
    "best_thresh = cv_NB()  # (score.mean(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fcfa4-b803-4214-8d6f-2886d5495bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on whole training set with reduced feature count (resulting from applying best threshold)\n",
    "X_train_nb, X_test_nb = best_thresh[1], best_thresh[2]\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_nb, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707e63c-1d33-46db-bb63-f71ae5f5c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_clf.predict(X_test_nb)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef497b30-fc11-4282-887f-84c725dae0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 10, 0.001)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbffcbf-9696-4796-af54-a5c61e701296",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d015b34-5bef-44d2-81e5-63ac296e5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "97431575-ce82-4db5-a0a6-dd12b42bef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Recall: 0.86\n",
      "Precision: 0.85\n",
      "F1: 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85625, 0.8625, 0.8518518518518519, 0.8571428571428572)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.arange(0.01, 10 ,0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "params = {'C': alphas}\n",
    "lr = GridSearchCV(LogisticRegression(penalty=\"l1\", solver=\"liblinear\"),  param_grid=params)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86209090-801f-4097-8ba4-aa7d3d44509c",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9c185-295a-4ff3-8ed1-b75642a8a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92558aa-f6b0-440f-b91e-3b10528c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to search\n",
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "alphas = [round(a, 2) for a in alphas]\n",
    "nmin = list(range(2, 26))\n",
    "minleaf = list(range(1, 11))\n",
    "\n",
    "params = {'min_samples_split': nmin, 'min_samples_leaf': minleaf, 'ccp_alpha': alphas}\n",
    "\n",
    "dt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b4069-4c02-477c-a31f-3a9eb8991678",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491dab5-64a7-4236-9758-b63ed30e3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('dt_uni.pkl', \"wb\")\n",
    "pickle.dump(dt_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acf262-326a-41c1-b9d0-0da4b42f1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c0b54-5db1-45d0-b07d-4e624a9d8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1567d-c049-4caf-ac4b-3bdbd805ef6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f718e70-59ba-49f1-a0d3-95c5a1367905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1413b7-a576-4560-b1b0-2aea8594bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "ntrees = [50, 100, 200, 300, 500]\n",
    "nfeats = list(range(10, 201, 10))\n",
    "\n",
    "cartesian_product = list(itertools.product(nmin, minleaf, ntrees, nfeats))\n",
    "\n",
    "params = [p for p in cartesian_product if p[1] * 2 <= p[0]]\n",
    "\n",
    "def train_rf(params):\n",
    "    \n",
    "    # Estimate best RF hyperparameters using OOB performance instead of CV\n",
    "    best_rf_clf = None\n",
    "    i = 0\n",
    "    for p in params:\n",
    "        rf_clf = RandomForestClassifier(n_estimators=p[2], min_samples_split=p[0],\n",
    "                                    min_samples_leaf=p[1], max_features=p[3],\n",
    "                                    oob_score=True, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        \n",
    "        if best_rf_clf is None:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        if rf_clf.oob_score_ > best_rf_clf.oob_score_:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        print(f'Iteration: {i}, OOB: {round(rf_clf.oob_score_, 2)}') \n",
    "    \n",
    "    return (rf_clf, rf_clf.oob_score_)\n",
    "\n",
    "# Start multiprocessing pool\n",
    "best_rf_clf = train_rf(params)\n",
    "# p = mp.Pool(processes=mp.cpu_count())\n",
    "# rf_clfs = p.map(train_rf, params)\n",
    "# p.close()\n",
    "# p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7820b-aa77-4f6f-8c7f-ec686778c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b3cb4-3fcd-4fbb-8179-c652cc511dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = max(rf_clfs, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e17628-1c13-4d6c-982d-9c71c9d1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('rf_uni.pkl', \"wb\")\n",
    "pickle.dump(best_rf_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccba63-2cff-4eea-9181-dcffc9c57d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ed27d-b795-4e28-8683-ff742c66e5c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models using unigrams **and** bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68706f-2f3a-4c30-9447-41426891cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff3332-870d-4bf8-b522-2079ee5badad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb676e03-ca25-4d90-815e-95c5e9047315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "397c637a-fe34-45bc-b435-a5f151d2c995",
   "metadata": {},
   "source": [
    "## Models using bigrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58075a2-78ef-449d-a94c-c9ef5fe26704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e7ece-7881-46f1-b0ab-d80378610b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264a083-e2e3-47c8-a506-346ef905615e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

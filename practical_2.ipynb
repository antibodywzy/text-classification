{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c669ff-a233-4034-b7cb-6214df110641",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text pre-processing & train/test set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b5dfef-854c-4d9f-8d00-56aec9b1c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dbe132-8819-46fb-b9b0-92e811ae8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e25b221-70e3-4311-ae07-c5c7f83d6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0598e12b-321c-48d4-b1e9-5b2bf396ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_train[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e590d02-e9cc-4659-beec-368f9fd6a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_train[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4329389e-0f68-46d8-9aff-25540e2520b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_test[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d026a776-5291-4a41-8166-af556783e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_test[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4c1da4-006d-4aae-81e3-3da8c0f40f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat deceptive and truthful dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306e899-4798-4ef1-a73a-419dca9e5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([deceptive_train, truthful_train, deceptive_test, truthful_test], axis=0).reset_index(drop=True)\n",
    "df\n",
    "#640-800 = test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68973e-c5ab-40fc-9fd9-9c8158624077",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Further text pre-processing \n",
    "\n",
    "- Tokenization\n",
    "- Lower-casing\n",
    "- Punctuation & Special character removal\n",
    "- Spelling correction\n",
    "- Stop-word removal\n",
    "- (Stemming (Porter)) *Skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78e5ed3-155a-4101-90aa-e535db7ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # stopwords.words('english')\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddaafcd-569a-4b58-b898-ce567df33f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in nltk.word_tokenize(x)]) # Tokenize\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word.lower() for word in x]) # Apply lower-casing\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in string.punctuation]) # Punctuation removal\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in ' '.join(stopwords.words('english'))]) # Stop word removal\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [re.sub(\"(?:\\W|\\d)+\", \"\", word) for word in x]) # Removing special chars and numbers\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word != \"\"]) # Remove empty strings\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [str(TextBlob(word).correct()) for word in x]) # Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd04f48-bcba-4d4b-a1cf-4e72ffca5ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hotel, located, mile, train, station, quite, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[made, reservation, hilton, chicago, believing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[people, think, hilton, think, luxury, know, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[husband, recently, stayed, stayed, hilton, ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wife, booked, room, hilton, chicago, three, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  [hotel, located, mile, train, station, quite, ...      0\n",
       "1  [made, reservation, hilton, chicago, believing...      0\n",
       "2  [people, think, hilton, think, luxury, know, w...      0\n",
       "3  [husband, recently, stayed, stayed, hilton, ch...      0\n",
       "4  [wife, booked, room, hilton, chicago, three, w...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle the df. Pickled the df in case the kernel dies when fitting the models, because the spelling correction above takes a while to execute\n",
    "df = pd.read_pickle(\"./df.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fb9867-2cb1-41d2-a4fb-04741db6aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to str to construct dtm with sklearn CountVectorizer\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f813387-d5fb-44d0-9403-0a115976f830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel located mile train station quite like tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>made reservation hilton chicago believing goin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people think hilton think luxury know wish hal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>husband recently stayed stayed hilton chicago ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wife booked room hilton chicago three weekend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  hotel located mile train station quite like tr...      0\n",
       "1  made reservation hilton chicago believing goin...      0\n",
       "2  people think hilton think luxury know wish hal...      0\n",
       "3  husband recently stayed stayed hilton chicago ...      0\n",
       "4  wife booked room hilton chicago three weekend ...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a8faa7-6b77-4108-aeb9-15f37c143a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high hopes hilton chicago sad say disappointed outrageous expensive two people one night expect pay park car offer free wife instead pay get internet room wait pm check even though flight morning rent car airport hotel offer transportation stress hilton chicago hotel bar either doubt stay\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Text\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97424070-aa83-4d06-9031-a38099a6fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Set ngram=1,2, 1,2 and 2,2 (only bigrams) and min_df (float 0-1) for Naive Bayes when needed (use diff thresholds 0.005 increment starting at 1% -> 10%).\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), min_df=1, lowercase=False)\n",
    "X = vectorizer.fit_transform(df[\"Text\"])\n",
    "# X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d3c544-5217-4f97-ba8e-14700719f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6504)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b341bb-91ec-4072-a0dc-ba6be085f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advances'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d99f-d4ab-48b2-a15e-df0777db4081",
   "metadata": {},
   "source": [
    "#### Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473e43a0-190f-48c2-977a-dc4e5574d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[0:640], df[\"Label\"][0:640].to_numpy()\n",
    "X_test, y_test = X[640:], df[\"Label\"][640:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62e3b7-4a19-41a4-b4a5-9213d01dae5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models using unigram only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d5ee94-9774-4956-851a-97b4bb87ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3939a21e-f149-4d43-b9f7-c013040b117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def performance_metrics(y_true, y_pred):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cf_matrix.ravel()\n",
    "    \n",
    "    accuracy = (tn+tp)/(tn+tp+fp+fn)\n",
    "    recall =  (tp)/(tp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    \n",
    "    return (accuracy, recall, precision, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56636b49-b51f-47f4-acce-34812e765b87",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79639b76-8ad8-4e17-800e-675f63cd76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65318f-3870-4004-b564-f27a07d407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_NB():\n",
    "    \n",
    "    # Find best threshold\n",
    "    \n",
    "    thresholds = np.arange(0.01, 10, 0.001)\n",
    "    \n",
    "    cv_scores = []\n",
    "    for thresh in thresholds:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,1), min_df=thresh, lowercase=False)\n",
    "        X = vectorizer.fit_transform(df[\"Text\"]) \n",
    "        X_train = X[0:640] # Only need to change X_train/test, y_train/test remains same (only removing/adding columns, not rows)\n",
    "        X_test = X[640:]\n",
    "        score = cross_val_score(MultinomialNB(), X_train, y_train)\n",
    "        cv_scores.append((score.mean(), X_train, X_test))\n",
    "    \n",
    "    return max(cv_scores, key=lambda x: x[0]) # Return X_train/X_test for which CV score was best (best doc frequency threshold)\n",
    "        \n",
    "best_thresh = cv_NB()  # (score.mean(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fcfa4-b803-4214-8d6f-2886d5495bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on whole training set with reduced feature count (resulting from applying best threshold)\n",
    "X_train_nb, X_test_nb = best_thresh[1], best_thresh[2]\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_nb, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707e63c-1d33-46db-bb63-f71ae5f5c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_clf.predict(X_test_nb)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef497b30-fc11-4282-887f-84c725dae0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 10, 0.001)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbffcbf-9696-4796-af54-a5c61e701296",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d015b34-5bef-44d2-81e5-63ac296e5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97431575-ce82-4db5-a0a6-dd12b42bef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86209090-801f-4097-8ba4-aa7d3d44509c",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e9c185-295a-4ff3-8ed1-b75642a8a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e92558aa-f6b0-440f-b91e-3b10528c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to search\n",
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "alphas = [round(a, 2) for a in alphas]\n",
    "nmin = list(range(2, 26))\n",
    "minleaf = list(range(1, 11))\n",
    "\n",
    "params = {'min_samples_split': nmin, 'min_samples_leaf': minleaf, 'ccp_alpha': alphas}\n",
    "\n",
    "dt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "845b4069-4c02-477c-a31f-3a9eb8991678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 241440 candidates, totalling 1207200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                       0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                       0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                       0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                       0.28, 0.29, ...],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                               12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                               20, 21, 22, 23, 24, 25]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5491dab5-64a7-4236-9758-b63ed30e3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('dt_uni.pkl', \"wb\")\n",
    "pickle.dump(dt_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94acf262-326a-41c1-b9d0-0da4b42f1065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.01, 'min_samples_leaf': 6, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa3c0b54-5db1-45d0-b07d-4e624a9d8c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Recall: 0.84\n",
      "Precision: 0.63\n",
      "F1: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66875, 0.8375, 0.6261682242990654, 0.7165775401069518)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1567d-c049-4caf-ac4b-3bdbd805ef6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f718e70-59ba-49f1-a0d3-95c5a1367905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1413b7-a576-4560-b1b0-2aea8594bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 1905, OOB: 0.85\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "ntrees = [50, 100, 200, 300, 500]\n",
    "nfeats = list(range(10, 201, 10))\n",
    "\n",
    "cartesian_product = list(itertools.product(nmin, minleaf, ntrees, nfeats))\n",
    "\n",
    "params = [p for p in cartesian_product if p[1] * 2 <= p[0]]\n",
    "\n",
    "def train_rf(params):\n",
    "    \n",
    "    # Estimate best RF hyperparameters using OOB performance instead of CV\n",
    "    best_rf_clf = None\n",
    "    i = 0\n",
    "    for p in params:\n",
    "        rf_clf = RandomForestClassifier(n_estimators=p[2], min_samples_split=p[0],\n",
    "                                    min_samples_leaf=p[1], max_features=p[3],\n",
    "                                    oob_score=True, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        \n",
    "        if best_rf_clf is None:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        if rf_clf.oob_score_ > best_rf_clf.oob_score_:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        print(f'Iteration: {i}, OOB: {round(rf_clf.oob_score_, 2)}') \n",
    "    \n",
    "    return (rf_clf, rf_clf.oob_score_)\n",
    "\n",
    "# Start multiprocessing pool\n",
    "best_rf_clf = train_rf(params)\n",
    "# p = mp.Pool(processes=mp.cpu_count())\n",
    "# rf_clfs = p.map(train_rf, params)\n",
    "# p.close()\n",
    "# p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b7820b-aa77-4f6f-8c7f-ec686778c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b3cb4-3fcd-4fbb-8179-c652cc511dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = max(rf_clfs, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e17628-1c13-4d6c-982d-9c71c9d1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('rf_uni.pkl', \"wb\")\n",
    "pickle.dump(best_rf_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccba63-2cff-4eea-9181-dcffc9c57d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ed27d-b795-4e28-8683-ff742c66e5c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models using unigrams **and** bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68706f-2f3a-4c30-9447-41426891cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff3332-870d-4bf8-b522-2079ee5badad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb676e03-ca25-4d90-815e-95c5e9047315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "397c637a-fe34-45bc-b435-a5f151d2c995",
   "metadata": {},
   "source": [
    "## Models using bigrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58075a2-78ef-449d-a94c-c9ef5fe26704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e7ece-7881-46f1-b0ab-d80378610b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264a083-e2e3-47c8-a506-346ef905615e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
